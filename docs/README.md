# FOCUS: Flow Matching & Diffusion Model for Cosmological Universe Simulation

A modular framework for training and using diffusion models and flow matching to generate 2D dark matter maps conditioned on cosmological parameters.

## ğŸŒŸ Features

- âœ… **Modular Architecture**: Clean separation of models, training, diffusion, and utilities
- âœ… **Conditional Generation**: Generate 2D dark matter maps from 6 cosmological parameters
- âœ… **DDPM/DDIM**: Full diffusion pipeline with DDPM and fast DDIM sampling
- âœ… **Classifier-Free Guidance (CFG)**: Improve generation quality
- âœ… **Experiment Management**: Organized task structure with YAML configs
- âœ… **Easy to Extend**: Ready for flow matching, new architectures, transformers, etc.
- âœ… **Verified**: Forward diffusion converges to N(0,1) distribution

## ğŸ“ Project Structure

```
cosmo/
â”œâ”€â”€ models/                  # Model architectures
â”‚   â”œâ”€â”€ embeddings.py        # Time/condition embeddings
â”‚   â””â”€â”€ unet.py              # UNet model (add transformers, etc.)
â”‚
â”œâ”€â”€ dataloaders/             # Data handling
â”‚   â”œâ”€â”€ cosmology_dataset.py # PyTorch Dataset
â”‚   â””â”€â”€ prepare_data.py      # Data preprocessing script
â”‚
â”œâ”€â”€ diffusion/               # Diffusion models
â”‚   â”œâ”€â”€ schedules.py         # Noise schedules (linear, cosine, quadratic)
â”‚   â””â”€â”€ ddpm.py              # DDPM/DDIM implementation
â”‚
â”œâ”€â”€ flowmatching/            # Flow matching models (future)
â”‚
â”œâ”€â”€ training/                # Training utilities
â”‚   â”œâ”€â”€ trainer.py           # Main trainer class
â”‚   â””â”€â”€ callbacks.py         # Early stopping, checkpointing, logging
â”‚
â”œâ”€â”€ utils/                   # Utility functions
â”‚   â”œâ”€â”€ normalization.py     # Data normalization/denormalization
â”‚   â”œâ”€â”€ visualization.py     # Plotting utilities
â”‚   â””â”€â”€ power_spectrum.py    # Power spectrum analysis
â”‚
â”œâ”€â”€ manifold_analysis/       # Manifold analysis (future)
â”‚
â”œâ”€â”€ parameter_inference/     # Parameter inference
â”‚   â”œâ”€â”€ inference.py         # Model loading and sampling
â”‚   â””â”€â”€ sampling.py          # Parameter sampling utilities
â”‚
â”œâ”€â”€ tasks/                   # Experiments
â”‚   â”œâ”€â”€ experiment_01/       # Example experiment
â”‚   â”‚   â”œâ”€â”€ config.yaml      # Experiment configuration
â”‚   â”‚   â”œâ”€â”€ checkpoints/     # Saved models
â”‚   â”‚   â”œâ”€â”€ logs/            # Training logs
â”‚   â”‚   â””â”€â”€ figs/            # Generated figures
â”‚   â”œâ”€â”€ train_experiment.py  # Training script
â”‚   â””â”€â”€ inference_experiment.py  # Inference script
â”‚
â”œâ”€â”€ configs/                 # Default configurations
â”‚   â””â”€â”€ default.yaml
â”‚
â”œâ”€â”€ scripts/                 # Testing & visualization scripts
â”‚   â”œâ”€â”€ visualize_data.py
â”‚   â”œâ”€â”€ test_diffusion.py
â”‚   â””â”€â”€ legacy/              # Old code versions (for reference)
â”‚
â”œâ”€â”€ train.py                 # Main training entry point
â”œâ”€â”€ inference.py             # Main inference entry point
â”œâ”€â”€ setup.py                 # Package setup
â””â”€â”€ requirements.txt         # Dependencies
```

## ğŸš€ Quick Start

### 1. Installation

```bash
pip install -r requirements.txt
```

Required packages:
- `torch >= 2.0.0`
- `numpy >= 1.24.0`
- `matplotlib >= 3.7.0`
- `scipy >= 1.10.0`
- `tqdm >= 4.65.0`
- `pyyaml` (for configs)

### 2. Prepare Data

Place your data in the following structure:
```
Data/
â””â”€â”€ 2D/
    â”œâ”€â”€ Maps_Mcdm_IllustrisTNG_LH_z=0.00.npy  # (15000, 256, 256)
    â””â”€â”€ params_LH_IllustrisTNG.txt             # (1000, 6)
```

Then run:
```bash
python dataloaders/prepare_data.py --data_dir ./Data --output_dir ./processed_data
```

### 3. Run an Experiment

Create a new experiment in `tasks/`:
```bash
mkdir -p tasks/my_experiment/{checkpoints,logs,figs}
cp configs/default.yaml tasks/my_experiment/config.yaml
```

Edit `tasks/my_experiment/config.yaml` to your liking, then train:
```bash
python tasks/train_experiment.py --config tasks/my_experiment/config.yaml --exp_dir tasks/my_experiment
```

### 4. Generate Samples

After training, generate samples:
```bash
python tasks/inference_experiment.py --config tasks/my_experiment/config.yaml --exp_dir tasks/my_experiment
```

## ğŸ“‹ Configuration

Edit `config.yaml` to customize:

```yaml
# Model architecture
model:
  base_channels: 64        # Model size (64/128/256)
  channel_mults: [1, 2, 4, 8]

# Diffusion schedule
diffusion:
  timesteps: 1000          # Number of diffusion steps
  schedule: "linear"       # linear/cosine/quadratic

# Training
training:
  batch_size: 2            # Adjust for GPU memory
  num_epochs: 200
  lr: 1.0e-4
  cfg_prob: 0.1           # 10% unconditional training

# Sampling
sampling:
  method: "ddim"          # ddim (fast) or ddpm (accurate)
  ddim_timesteps: 50
  cfg_scale: 2.0
```

## ğŸ”§ Module Usage

### Models
```python
from models import SimpleUNet

model = SimpleUNet(
    in_channels=1,
    out_channels=1,
    cond_dim=6,
    base_channels=64,
    channel_mults=(1, 2, 4, 8),
)
```

### Diffusion
```python
from diffusion import GaussianDiffusion

diffusion = GaussianDiffusion(
    timesteps=1000,
    beta_start=1e-4,
    beta_end=0.02,
    schedule='linear',
    device='cuda'
)
```

### Training
```python
from training import DiffusionTrainer

trainer = DiffusionTrainer(
    model=model,
    diffusion=diffusion,
    train_loader=train_loader,
    val_loader=val_loader,
    device='cuda',
    lr=1e-4,
    cfg_prob=0.1,
    output_dir='./outputs'
)

trainer.train(num_epochs=200)
```

## ğŸ¯ Future Extensions

This framework is designed to be easily extended:

1. **New Noise Schedules**: Add to `diffusion/schedules.py`
2. **New Models**: Add to `models/` (e.g., transformer-based architectures)
3. **Flow Matching**: Implement in `flowmatching/`
4. **Parameter Inference**: Add to `parameter_inference/`
5. **Manifold Analysis**: Add to `manifold_analysis/`

## ğŸ“Š Performance

| GPU | Batch Size | Training Time (100 epochs) | Memory |
|-----|-----------|----------------------------|--------|
| A100 | 16 | ~3 hours | ~14 GB |
| RTX 3090 | 8 | ~5 hours | ~8 GB |
| RTX 3080 | 4 | ~10 hours | ~6 GB |

## ğŸ› Troubleshooting

### CUDA Out of Memory
```yaml
training:
  batch_size: 1  # Reduce batch size
model:
  base_channels: 32  # Reduce model size
```

### Training Too Slow
```yaml
sampling:
  ddim_timesteps: 20  # Reduce sampling steps during training
```

### Poor Generation Quality
- Train longer (increase `num_epochs`)
- Increase model size (`base_channels: 128`)
- Adjust CFG scale in inference

## ğŸ“š References

- **DDPM**: [Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239)
- **DDIM**: [Denoising Diffusion Implicit Models](https://arxiv.org/abs/2010.02502)
- **Classifier-Free Guidance**: [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598)

## ğŸ“„ License

This project is for research purposes.

## ğŸ¤ Contributing

Issues and PRs are welcome!

---

**Happy Generating!** ğŸš€
