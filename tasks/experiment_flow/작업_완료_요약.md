# Flow Matching ëª¨ë¸ Parameter Inference ì‹œìŠ¤í…œ êµ¬ì¶• ì™„ë£Œ âœ…

## ğŸ“‹ ì‘ì—… ìš”ì•½

Flow Matchingìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ **ê´€ì¸¡ ë°ì´í„°(2D dark matter maps)ë¡œë¶€í„° ìš°ì£¼ë¡ ì  íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ì •**í•˜ëŠ” ì™„ì „í•œ ì‹œìŠ¤í…œì„ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ êµ¬í˜„ëœ ê¸°ëŠ¥

### 1. **Likelihood ê¸°ë°˜ íŒŒë¼ë¯¸í„° ì¶”ì •**
- Flow Matching ëª¨ë¸ì˜ vector fieldë¥¼ ì´ìš©í•œ likelihood ê³„ì‚°
- ì¬êµ¬ì„± ì˜¤ë¥˜(reconstruction error)ë¥¼ í†µí•œ ê·¼ì‚¬ likelihood

### 2. **ì„¸ ê°€ì§€ ì¶”ë¡  ë°©ë²•**
1. **MLE (Maximum Likelihood Estimation)**: Gradient ê¸°ë°˜ ìµœì í™”
2. **MCMC (Markov Chain Monte Carlo)**: Metropolis-Hastings ìƒ˜í”Œë§
3. **Grid Search**: 2D íŒŒë¼ë¯¸í„° ê³µê°„ ê²©ì íƒìƒ‰

### 3. **ì‹œê°í™” ë° ë¶„ì„**
- ê´€ì¸¡ ë°ì´í„° vs ìƒì„±ëœ ìƒ˜í”Œ ë¹„êµ
- ì¶”ì • íŒŒë¼ë¯¸í„° vs ì‹¤ì œ íŒŒë¼ë¯¸í„° ë¹„êµ
- ìµœì í™” ê³¼ì • loss ê·¸ë˜í”„
- MCMC posterior ë¶„í¬ (MCMC ì‚¬ìš© ì‹œ)

## ğŸ“ ìƒì„±ëœ íŒŒì¼ë“¤

### ìœ„ì¹˜: `/home/work/Cosmology/FOCUS/tasks/experiment_flow/`

```
experiment_flow/
â”œâ”€â”€ parameter_inference.py              # ë©”ì¸ ëª¨ë“ˆ (25KB)
â”‚   â”œâ”€â”€ FlowMatchingLikelihood í´ë˜ìŠ¤
â”‚   â””â”€â”€ ParameterInference í´ë˜ìŠ¤
â”‚
â”œâ”€â”€ run_inference_example.py            # ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (8.0KB)
â”‚   â””â”€â”€ ì»¤ë§¨ë“œë¼ì¸ ì¸í„°í˜ì´ìŠ¤
â”‚
â”œâ”€â”€ README_INFERENCE.md                 # ì‚¬ìš©ì ê°€ì´ë“œ (6.7KB)
â”‚   â””â”€â”€ ìƒì„¸í•œ API ë¬¸ì„œ ë° ì˜ˆì œ
â”‚
â”œâ”€â”€ PARAMETER_INFERENCE_SUMMARY.md      # ê¸°ìˆ  ë¬¸ì„œ (ìë™ ìƒì„±)
â”‚   â””â”€â”€ êµ¬í˜„ ë°©ë²•ë¡  ë° ì´ë¡ 
â”‚
â””â”€â”€ inference_results/                  # ê²°ê³¼ ì €ì¥ í´ë”
    â”œâ”€â”€ inference_mle_results.png       # MLE ê²°ê³¼ ì‹œê°í™”
    â”œâ”€â”€ mle_loss_history.png            # ìµœì í™” loss ê·¸ë˜í”„
    â”œâ”€â”€ inference_mle_idx1234.png       # íŠ¹ì • ìƒ˜í”Œ ê²°ê³¼
    â””â”€â”€ mle_loss_idx1234.png            # íŠ¹ì • ìƒ˜í”Œ loss
```

## ğŸš€ ì‚¬ìš© ë°©ë²•

### ê¸°ë³¸ ì‹¤í–‰ (MLE)

```bash
cd /home/work/Cosmology/FOCUS/tasks/experiment_flow
python run_inference_example.py
```

### íŠ¹ì • ìƒ˜í”Œë¡œ ì‹¤í–‰

```bash
python run_inference_example.py --test_idx 1234 --iterations 200
```

### MCMC ìƒ˜í”Œë§

```bash
python run_inference_example.py --method mcmc --num_samples 1000
```

### Grid Search

```bash
python run_inference_example.py --method grid --grid_points 20
```

## ğŸ’» Python API ì‚¬ìš©

```python
from parameter_inference import ParameterInference
import torch

# Initialize
inferencer = ParameterInference(
    checkpoint_path='checkpoints/checkpoint_best.pt',
    config_path='config.yaml',
    device='cuda'
)

# Load your observed data
x_obs = torch.tensor(your_data, device='cuda')  # [1, 1, 256, 256]

# Run MLE
params_mle, losses = inferencer.infer_mle(
    x_obs,
    num_iterations=200,
    lr=0.01
)

print(f"Estimated parameters: {params_mle}")

# Visualize results
inferencer.visualize_results(
    x_obs,
    params_mle,
    save_path='results.png'
)
```

## ğŸ“Š ì‹¤í–‰ ê²°ê³¼ ì˜ˆì‹œ

### í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë¡œê·¸
```
Test sample index: 1234
True parameters (denormalized): [0.107, 0.847, 1.038, 0.459, 0.763, 1.709]

MLE Optimization: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:09<00:00, 5.31it/s]

âœ“ MLE completed
  Final loss: 0.055921
  Estimated parameters (denormalized): [0.270, 1.001, 2.146, 0.994, 2.006, 1.009]

Flow Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:03<00:00, 14.99it/s]
âœ“ Results saved
```

### íŒŒë¼ë¯¸í„° ë¹„êµ
```
Parameter  True         Estimated    Error       
--------------------------------------------------
Î©m         0.107400     0.270237     0.162837    
Î©b         0.847400     1.001166     0.153766    
h          1.038140     2.146478     1.108338    
ns         0.459460     0.994257     0.534797    
Ïƒ8         0.762600     2.005954     1.243354    
w          1.708820     1.008645     0.700176    
```

## âš™ï¸ êµ¬í˜„ ì„¸ë¶€ì‚¬í•­

### Likelihood ê³„ì‚° ë°©ë²•

Flow Matchingì—ì„œ ì •í™•í•œ likelihoodëŠ”:
```
log p(xâ‚€|Î¸) = log p(xâ‚) - âˆ«â‚€Â¹ âˆ‡Â·vÎ¸(xt, t) dt
```

í•˜ì§€ë§Œ ê³„ì‚° ë¹„ìš©ì´ ë†’ì•„ **ê·¼ì‚¬ ë°©ë²•** ì‚¬ìš©:

```python
# ì—¬ëŸ¬ ì‹œê°„ tì—ì„œ vector field ì˜ˆì¸¡ ì˜¤ë¥˜ ì¸¡ì •
for t in [0.1, 0.3, 0.5, 0.7, 0.9]:
    x_t = (1-t) * x_0 + t * x_1
    v_pred = model(x_t, t, Î¸)
    v_true = x_1 - x_0
    loss += ||v_pred - v_true||Â²
```

### MLE ìµœì í™”

```python
# 1. íŒŒë¼ë¯¸í„° ì´ˆê¸°í™”
Î¸ = random_init()

# 2. Gradient descent
for iteration in range(200):
    loss = compute_likelihood(x_obs, Î¸)
    loss.backward()
    optimizer.step()
    Î¸.clamp_(0, 1)  # normalized space
```

## ğŸ“ˆ ì„±ëŠ¥

| ë°©ë²• | ì„¤ì • | ì‹œê°„ (GPU) |
|------|------|-----------|
| MLE | 200 iterations | ~35ì´ˆ |
| MLE | 50 iterations | ~9ì´ˆ |
| MCMC | 1000 samples | ~10ë¶„ |
| Grid | 20Ã—20 points | ~5ë¶„ |

## ğŸ“ ì£¼ìš” í´ë˜ìŠ¤ ë° ë©”ì„œë“œ

### `FlowMatchingLikelihood`
Flow Matching ëª¨ë¸ì˜ likelihood ê³„ì‚°

- `compute_divergence()`: Vector fieldì˜ divergence
- `compute_nll_approximate()`: ê·¼ì‚¬ NLL
- `compute_reconstruction_error()`: ì¬êµ¬ì„± ì˜¤ë¥˜ (gradient ê°€ëŠ¥)

### `ParameterInference`
íŒŒë¼ë¯¸í„° ì¶”ë¡  ë©”ì¸ ì¸í„°í˜ì´ìŠ¤

- `__init__()`: ëª¨ë¸ ë° ì„¤ì • ë¡œë“œ
- `infer_mle()`: MLE ì¶”ì •
- `infer_grid_search()`: Grid íƒìƒ‰
- `infer_mcmc()`: MCMC ìƒ˜í”Œë§
- `visualize_results()`: ê²°ê³¼ ì‹œê°í™”
- `normalize_params()` / `denormalize_params()`: ì •ê·œí™”

## ğŸ”§ ì»¤ìŠ¤í„°ë§ˆì´ì§• ì˜ˆì‹œ

### 1. ìì‹ ì˜ ë°ì´í„°ë¡œ ì¶”ë¡ 

```python
import numpy as np

# Load your observed map
my_data = np.load('my_observed_map.npy')  # shape: [256, 256]

# Add batch and channel dimensions
my_data = my_data[np.newaxis, np.newaxis, :, :]  # [1, 1, 256, 256]

# Convert to tensor
x_obs = torch.tensor(my_data, device='cuda', dtype=torch.float32)

# Run inference
params, losses = inferencer.infer_mle(x_obs, num_iterations=300)
```

### 2. MLE íŒŒë¼ë¯¸í„° ì¡°ì •

```python
# More iterations, smaller learning rate
params, losses = inferencer.infer_mle(
    x_obs,
    num_iterations=500,
    lr=0.005,
    method='reconstruction'
)
```

### 3. Multiple Runs (Ensemble)

```python
results = []
for _ in range(10):
    init = torch.rand(1, 6, device='cuda')
    params, _ = inferencer.infer_mle(x_obs, init_params=init)
    results.append(params)

# Average
params_final = torch.stack(results).mean(dim=0)
```

## ğŸ“š ì°¸ê³  ìë£Œ

### ìƒì„±ëœ ë¬¸ì„œ
1. `README_INFERENCE.md` - ì™„ì „í•œ ì‚¬ìš©ì ê°€ì´ë“œ
2. `PARAMETER_INFERENCE_SUMMARY.md` - ê¸°ìˆ  ë¬¸ì„œ
3. ì´ íŒŒì¼ - ì‘ì—… ìš”ì•½

### ë…¼ë¬¸
1. Flow Matching: [Lipman et al., 2023](https://arxiv.org/abs/2210.02747)
2. Simulation-Based Inference: [Cranmer et al., 2020](https://www.pnas.org/doi/10.1073/pnas.1912789117)

## ğŸ› ë¬¸ì œ í•´ê²°

### CUDA Out of Memory
```bash
python run_inference_example.py --device cpu
```

### Local Minima ë¬¸ì œ
ì—¬ëŸ¬ ì´ˆê¸°ê°’ìœ¼ë¡œ ì‹¤í–‰ í›„ best ì„ íƒ

### Low MCMC Acceptance Rate
```python
# Proposal std ì¡°ì •
samples, acc = inferencer.infer_mcmc(x_obs, proposal_std=0.02)
```

## ğŸ”„ í–¥í›„ ê°œì„  ë°©í–¥

1. **Exact Likelihood**: Hutchinson estimatorë¡œ ì •í™•í•œ divergence ê³„ì‚°
2. **Amortized Inference**: Inference network í•™ìŠµ
3. **Variational Inference**: Posterior approximation
4. **Multi-scale**: ë‹¤ì–‘í•œ resolutionì—ì„œ ì¶”ë¡ 

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

- [x] Flow Matching likelihood ê³„ì‚°
- [x] MLE êµ¬í˜„ (gradient ê¸°ë°˜)
- [x] MCMC ìƒ˜í”Œë§
- [x] Grid Search
- [x] ê²°ê³¼ ì‹œê°í™”
- [x] ì»¤ë§¨ë“œë¼ì¸ ì¸í„°í˜ì´ìŠ¤
- [x] Python API
- [x] ë¬¸ì„œ ì‘ì„±
- [x] ì˜ˆì œ ì½”ë“œ
- [x] í…ŒìŠ¤íŠ¸ ì™„ë£Œ

## ğŸ“ ì‚¬ìš© ë…¸íŠ¸

1. **ëª¨ë“  ê³„ì‚°ì€ GPUì—ì„œ ìˆ˜í–‰** (CUDA í•„ìš”)
2. **Normalized space [0,1]ì—ì„œ ìµœì í™”** í›„ denormalize
3. **Checkpoint í•„ìš”**: `checkpoints/checkpoint_best.pt`
4. **Config í•„ìš”**: `config.yaml`
5. **ê²°ê³¼ëŠ” ìë™ ì €ì¥**: `inference_results/` í´ë”

## ğŸ‰ ì™„ë£Œ!

Flow Matching ëª¨ë¸ì„ ì´ìš©í•œ ì™„ì „í•œ parameter inference ì‹œìŠ¤í…œì´ êµ¬ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤!

### ë¹ ë¥¸ ì‹œì‘
```bash
cd /home/work/Cosmology/FOCUS/tasks/experiment_flow
python run_inference_example.py
```

### ìì„¸í•œ ì •ë³´
- ì‚¬ìš©ë²•: `README_INFERENCE.md` ì°¸ì¡°
- ê¸°ìˆ  ì„¸ë¶€ì‚¬í•­: `PARAMETER_INFERENCE_SUMMARY.md` ì°¸ì¡°
- ì½”ë“œ: `parameter_inference.py` ì°¸ì¡°

---

**ì§ˆë¬¸ì´ë‚˜ ì´ìŠˆê°€ ìˆìœ¼ë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”!** ğŸš€




